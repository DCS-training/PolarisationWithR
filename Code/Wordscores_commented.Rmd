---
title: "Polarization Analysis using Wordscores in R"
author: "Unai GÓMEZ-HERNÁNDEZ"
date: "`r Sys.Date()`"
output: html_document
---

# Install & Load Required Packages

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r install-packages, eval=FALSE}
#install.packages("usethis")
library(usethis)
library(devtools)
#devtools::install_github("quanteda/quanteda.textmodels", dependencies = TRUE)
```

```{r load-libraries}
library(dplyr)
library(readr)
library(stringr)
library(quanteda.textmodels)
library(quanteda)
library(ggplot2)
```

# Load Dataset

```{r load-data}
data <- read_csv("../Data/EU-China_resolutions.csv")  # Read CSV file
head(data)  # View first few rows of the dataset
```

# Select Reference Documents and Assign Random Scores

```{r reference-docs}
set.seed(123)  # Ensure reproducibility
sample_docs <- data %>%
  sample_n(10)  # Randomly select 10 documents

# Assign random scores between -2 and +2
df_reference <- sample_docs %>%
  mutate(reference_score = sample(-2:2, 10, replace = TRUE))

print(df_reference)  # Display selected texts with assigned scores
```

# Merge Randomly Scored Reference Documents with Original Data

```{r merge-data}
data <- data %>%
  left_join(df_reference %>%
              select(full_text, reference_score), by = "full_text")
```

# Tokenize Text and Create a Document-Feature Matrix (DFM)

```{r tokenize-text}
# Tokenize the text while removing punctuation
tokens_ref <- tokens(df_reference$full_text, remove_punct = TRUE)

# Create a document-feature matrix (DFM) from the tokenized text
dfm_ref <- dfm(tokens_ref)

# Remove English stopwords from the DFM to focus on meaningful words
dfm_ref <- dfm_remove(dfm_ref, pattern = stopwords("en"))

```

# Train Wordscores Model

```{r train-model}
ws_model <- textmodel_wordscores(dfm_ref, y = df_reference$reference_score)
```

# Apply Wordscores Model to Unscored Documents

```{r apply-model}
# Select documents that do not have a reference score
virgin_docs <- data %>%
  filter(is.na(reference_score)) %>%
  select(full_text)  

# Tokenize unscored documents, removing punctuation
tokens_virgin <- tokens(virgin_docs$full_text, remove_punct = TRUE)

# Create a document-feature matrix (DFM)
dfm_virgin <- dfm(tokens_virgin)

# Remove English stopwords from the DFM
dfm_virgin <- dfm_remove(dfm_virgin, pattern = stopwords("en"))  

# Predict sentiment scores for unscored documents using the WordScores model
predicted_scores <- predict(ws_model, newdata = dfm_virgin)  
```

# Assign Predicted Scores to Data and Save

```{r assign-predictions}
data$predicted_score <- NA  # Initialize predicted score column
data$predicted_score[is.na(data$reference_score)] <- predicted_scores  # Assign predictions
write_csv(data, "EU-China_resolutions_with_scores.csv")  # Save updated dataset
```

# Visualize the Polarization Distribution

```{r plot-distribution}
ggplot(data, aes(x = predicted_score)) +
  geom_histogram(binwidth = 0.5, fill = "steelblue", color = "black", alpha = 0.7) +  # Improve aesthetics
  theme_minimal() +  # Apply minimal theme
  labs(title = "Polarization of EU-China Resolutions", x = "Predicted Score", y = "Frequency") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        axis.title = element_text(face = "bold"),
        axis.text = element_text(size = 12))
```

# 10. Repeat Process with Fixed Reference Documents

```{r fixed-reference}
data <- read_csv("../Data/EU-China_resolutions.csv")  # Reload original dataset

# Ensure reference documents exist in dataset based on "resolution code"
df_fixed_reference <- data %>% filter(resolution_code %in% c("P4_1998/0293", "P6_2009/0053"))

# Check if documents exist before proceeding
if (nrow(df_fixed_reference) < 2) {
  stop("Error: One or both reference documents are missing from the dataset.")
}

# Assign fixed reference scores
df_fixed_reference <- df_fixed_reference %>%
  mutate(reference_score = ifelse(resolution_code == "P4_1998/0293", -2, 2))

print(df_fixed_reference)  # Display selected reference documents

# Tokenize & Create DFM using full text
tokens_fixed_ref <- tokens(df_fixed_reference$full_text, remove_punct = TRUE)
dfm_fixed_ref <- dfm(tokens_fixed_ref)
dfm_fixed_ref <- dfm_remove(dfm_fixed_ref, pattern = stopwords("en"))

# Check if DFM has at least one feature
if (nfeat(dfm_fixed_ref) == 0) {
  stop("Error: The document-feature matrix is empty after preprocessing. Consider reducing stopword removal.")
}

# Train Wordscores Model on Fixed References
ws_fixed_model <- textmodel_wordscores(dfm_fixed_ref, y = df_fixed_reference$reference_score)

# Apply Model to Unscored Documents
virgin_docs_fixed <- data %>% filter(!resolution_code %in% c("P4_1998/0293", "P6_2009/0053")) %>% select(full_text)
tokens_virgin_fixed <- tokens(virgin_docs_fixed$full_text, remove_punct = TRUE)
dfm_virgin_fixed <- dfm(tokens_virgin_fixed)
dfm_virgin_fixed <- dfm_remove(dfm_virgin_fixed, pattern = stopwords("en"))

# Check if the DFM is non-empty before prediction
if (nfeat(dfm_virgin_fixed) == 0) {
  stop("Error: The DFM for unscored documents is empty. Consider adjusting preprocessing steps.")
}

predicted_scores_fixed <- predict(ws_fixed_model, newdata = dfm_virgin_fixed)

# Assign Fixed Model Predicted Scores
data$predicted_score_fixed <- NA
data$predicted_score_fixed[!data$resolution_code %in% c("P4_1998/0293", "P6_2009/0053")] <- predicted_scores_fixed
write_csv(data, "EU-China_resolutions_with_fixed_scores.csv")

# Visualize Fixed Model Results
ggplot(data, aes(x = predicted_score_fixed)) +
  geom_histogram(binwidth = 0.5, fill = "red", alpha = 0.6) +
  theme_minimal() +
  labs(title = "Polarization with Fixed Reference Scores", x = "Predicted Score", y = "Count")
```
